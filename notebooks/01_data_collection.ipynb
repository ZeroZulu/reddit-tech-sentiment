{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b2c823",
   "metadata": {},
   "source": [
    "# 01 — Data Collection (Kaggle Datasets)\n",
    "\n",
    "**Objective:** Load real Reddit post data from Kaggle datasets, clean and standardize columns, store in SQLite, and prepare for NLP analysis.\n",
    "\n",
    "**Data Sources:**\n",
    "- `data_science.csv` — 500K+ posts/comments from r/datascience (Kaggle)\n",
    "- `reddit_posts.csv` — Multi-subreddit Reddit posts dataset (Kaggle)\n",
    "\n",
    "**Note:** These datasets replace the Reddit API scraper. The rest of the pipeline (preprocessing, sentiment, topics, dashboard) works identically with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196976ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-25 15:40:53.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36mload_config\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mConfiguration loaded from ..\\config\\config.yaml\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project config loaded\n",
      "Target subreddits: ['technology', 'datascience', 'MachineLearning', 'cscareerquestions', 'programming']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "from src.utils import load_config, get_db_connection, init_database\n",
    "\n",
    "config = load_config('../config/config.yaml')\n",
    "print(\"Project config loaded\")\n",
    "print(\"Target subreddits:\", config['reddit']['subreddits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8094ab9",
   "metadata": {},
   "source": [
    "## 1.1 Load the Data Science Dataset\n",
    "\n",
    "This dataset contains posts AND comments from r/datascience. We filter to posts only (comments have title=\"Comment\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0791294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21,095 rows from data_science.csv\n",
      "After filtering comments: 1,870 actual posts\n",
      "\n",
      "Date range: 2021-12-08 22:45:24+00:00 to 2022-04-22 08:57:43+00:00\n",
      "Avg score: 51.6\n",
      "Null selftext: 201\n"
     ]
    }
   ],
   "source": [
    "# Load data_science.csv\n",
    "# Adjust the path to wherever your CSV is located\n",
    "ds_path = '../data/raw/data_science.csv'\n",
    "\n",
    "if os.path.exists(ds_path):\n",
    "    df_ds = pd.read_csv(ds_path, low_memory=False)\n",
    "    print(f\"Loaded {len(df_ds):,} rows from data_science.csv\")\n",
    "    \n",
    "    # Filter out comments — keep only actual posts\n",
    "    df_ds = df_ds[df_ds['title'] != 'Comment'].copy()\n",
    "    print(f\"After filtering comments: {len(df_ds):,} actual posts\")\n",
    "    \n",
    "    # Standardize columns to match our pipeline\n",
    "    df_ds = df_ds.rename(columns={\n",
    "        'comms_num': 'num_comments',\n",
    "        'body': 'selftext',\n",
    "        'created': 'created_utc_raw',\n",
    "    })\n",
    "    \n",
    "    # Add subreddit column\n",
    "    df_ds['subreddit'] = 'datascience'\n",
    "    \n",
    "    # Parse timestamps\n",
    "    df_ds['created_utc'] = pd.to_datetime(df_ds['created_utc_raw'], unit='s', utc=True, errors='coerce')\n",
    "    \n",
    "    # Fill missing columns\n",
    "    df_ds['upvote_ratio'] = 0.85  # Default estimate\n",
    "    df_ds['author'] = 'kaggle_user'\n",
    "    \n",
    "    # Select standard columns\n",
    "    ds_cols = ['id', 'subreddit', 'title', 'selftext', 'score', 'num_comments', 'created_utc', 'upvote_ratio', 'author']\n",
    "    df_ds = df_ds[[c for c in ds_cols if c in df_ds.columns]].copy()\n",
    "    \n",
    "    print(f\"\\nDate range: {df_ds['created_utc'].min()} to {df_ds['created_utc'].max()}\")\n",
    "    print(f\"Avg score: {df_ds['score'].mean():.1f}\")\n",
    "    print(f\"Null selftext: {df_ds['selftext'].isna().sum()}\")\n",
    "    df_ds.head()\n",
    "else:\n",
    "    print(f\"File not found: {ds_path}\")\n",
    "    print(\"Make sure data_science.csv is in data/raw/\")\n",
    "    df_ds = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e0fb0",
   "metadata": {},
   "source": [
    "## 1.2 Load the Reddit Posts Dataset\n",
    "\n",
    "This is the multi-subreddit dataset. We filter to tech-related subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89870d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: ../data/raw/reddit_database.csv\n",
      "Loaded 545,427 rows\n",
      "Columns: ['created_date', 'created_timestamp', 'subreddit', 'title', 'id', 'author', 'author_created_utc', 'full_link', 'score', 'num_comments', 'num_crossposts', 'subreddit_subscribers', 'post']\n",
      "Subreddits: subreddit\n",
      "MachineLearning         121385\n",
      "datascience              67743\n",
      "statistics               61382\n",
      "learnmachinelearning     44217\n",
      "computerscience          43780\n",
      "AskStatistics            34472\n",
      "artificial               34292\n",
      "analytics                17008\n",
      "datasets                 16914\n",
      "deeplearning             16159\n",
      "rstats                   15684\n",
      "computervision           15655\n",
      "DataScienceJobs          14610\n",
      "MLQuestions              13462\n",
      "dataengineering          11861\n",
      "data                      8440\n",
      "dataanalysis              5897\n",
      "datascienceproject        1839\n",
      "kaggle                     627\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered to tech subreddits: ['datascience', 'MachineLearning', 'analytics', 'dataengineering', 'artificial', 'computerscience']\n",
      "Posts after filtering: 296,069\n",
      "Date range: 2008-06-23 18:50:07+00:00 to 2022-05-08 19:18:07+00:00\n"
     ]
    }
   ],
   "source": [
    "# Load the larger reddit posts dataset\n",
    "# Try common filenames — adjust if yours is different\n",
    "possible_paths = [\n",
    "    '../data/raw/reddit_database.csv',\n",
    "    '../data/raw/sample.xlsx',\n",
    "    '../data/raw/Reddit Top Posts.csv',\n",
    "    '../data/raw/reddit_top_posts.csv',\n",
    "]\n",
    "\n",
    "df_posts = pd.DataFrame()\n",
    "\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found: {path}\")\n",
    "        if path.endswith('.xlsx'):\n",
    "            df_posts = pd.read_excel(path)\n",
    "        else:\n",
    "            df_posts = pd.read_csv(path, low_memory=False)\n",
    "        print(f\"Loaded {len(df_posts):,} rows\")\n",
    "        break\n",
    "\n",
    "if len(df_posts) > 0:\n",
    "    print(f\"Columns: {list(df_posts.columns)}\")\n",
    "    print(f\"Subreddits: {df_posts['subreddit'].value_counts().head(20)}\")\n",
    "    \n",
    "    # Standardize columns\n",
    "    rename_map = {\n",
    "        'created_date': 'created_utc',\n",
    "        'created_timestamp': 'created_utc_unix',\n",
    "        'num_comments': 'num_comments',\n",
    "        'post': 'selftext',\n",
    "        'full_link': 'url',\n",
    "    }\n",
    "    df_posts = df_posts.rename(columns={k: v for k, v in rename_map.items() if k in df_posts.columns})\n",
    "    \n",
    "    # Parse timestamps\n",
    "    if 'created_utc' in df_posts.columns:\n",
    "        df_posts['created_utc'] = pd.to_datetime(df_posts['created_utc'], utc=True, errors='coerce')\n",
    "    elif 'created_utc_unix' in df_posts.columns:\n",
    "        df_posts['created_utc'] = pd.to_datetime(df_posts['created_utc_unix'], unit='s', utc=True, errors='coerce')\n",
    "    \n",
    "    # Fill missing columns\n",
    "    if 'upvote_ratio' not in df_posts.columns:\n",
    "        df_posts['upvote_ratio'] = 0.85\n",
    "    if 'author' not in df_posts.columns:\n",
    "        df_posts['author'] = 'kaggle_user'\n",
    "    \n",
    "    # Filter to tech-related subreddits if multiple exist\n",
    "    tech_subs = ['technology', 'datascience', 'MachineLearning', 'cscareerquestions', \n",
    "                 'programming', 'analytics', 'dataengineering', 'learnpython',\n",
    "                 'Python', 'artificial', 'computerscience', 'coding']\n",
    "    \n",
    "    available_tech = [s for s in tech_subs if s in df_posts['subreddit'].unique()]\n",
    "    if available_tech:\n",
    "        df_posts = df_posts[df_posts['subreddit'].isin(available_tech)]\n",
    "        print(f\"\\nFiltered to tech subreddits: {available_tech}\")\n",
    "    \n",
    "    print(f\"Posts after filtering: {len(df_posts):,}\")\n",
    "    print(f\"Date range: {df_posts['created_utc'].min()} to {df_posts['created_utc'].max()}\")\n",
    "else:\n",
    "    print(\"No reddit posts file found. Listing files in data/raw/:\")\n",
    "    for f in os.listdir('../data/raw/'):\n",
    "        print(f\"  {f}\")\n",
    "    print(\"\\nRename your file or update the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0fe184",
   "metadata": {},
   "source": [
    "## 1.3 Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf7d83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Science posts: 1,870\n",
      "Reddit Posts dataset: 296,069\n",
      "\n",
      "==================================================\n",
      "COMBINED DATASET\n",
      "==================================================\n",
      "Total posts: 296,192\n",
      "Subreddits: 6\n",
      "Date range: 2008-06-23 to 2022-05-08\n",
      "\n",
      "Subreddit distribution:\n",
      "subreddit\n",
      "MachineLearning    121385\n",
      "datascience         67866\n",
      "computerscience     43780\n",
      "artificial          34292\n",
      "analytics           17008\n",
      "dataengineering     11861\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Score stats:\n",
      "count    296192.0\n",
      "mean          5.2\n",
      "std          34.5\n",
      "min           0.0\n",
      "25%           1.0\n",
      "50%           1.0\n",
      "75%           1.0\n",
      "max        8331.0\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "selftext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_comments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_utc",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "upvote_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "775cc6c0-a872-4767-ac8f-e742df102f90",
       "rows": [
        [
         "0",
         "swvi7j",
         "datascience",
         "STEM Career Change",
         "I’m currently working as a field biologist for fisheries research, and am looking to transfer into a more data-science oriented career field. I’ve grown tired of the field work side and love the data side, while most of my coworkers are the opposite.\n\nI have a M.S. in Environmental Science, with coursework in single and multivariate stats, although I don’t use very much complicated math in my job. I have more experience than most of my early-career coworkers with R, and do use it at work, but am light years behind the statisticians in my office. No experience in Python, SQL, or any other data science software. \n\nMy questions would be:\n\n1. What skills would I need to gain / build on before making the switch? \n\n2. What’s a reasonable entry salary? Biologists don’t make great money so almost anything would be an increase haha.  \n\n3. Are online courses / certifications worth it? The amount of marketing I see for those is insane. \n\nI luckily have access to large amounts of data and free time to learn new skills at my job, so I just want to make sure I’m on the right path. Thanks in advance!",
         "5",
         "6",
         "2022-02-20 07:17:13+00:00",
         "0.85",
         "kaggle_user"
        ],
        [
         "1",
         "rc6wjp",
         "datascience",
         "Beast practices or frameworks for defining success metrics?",
         "I'd love to learn what framework folks use for defining feature success metrics. At a high level, I usually bucket my metrics under these areas: engagement, health, and Satisfaction. Revenue is usually not a focus for my team so I exclude. Within each category info through an exercise to understand what success would look like, example under engagement - metrics to understand how many people are using the feature (slice by various dimensions) over time etc\n\n. Does anyone have a framework or approach they can share?",
         "9",
         "2",
         "2021-12-09 02:00:48+00:00",
         "0.85",
         "kaggle_user"
        ],
        [
         "2",
         "rc5knh",
         "datascience",
         "Data Scientist VS Product/Project manager role",
         "Hey everyone, I am currently a Sr. Analyst and love all the math and ML behind machine learning(still learning), I see my fresher friends jumping into product manager roles and earning 2X their previous salaries, I am a quiet introverted nerd and maybe that's the reason I would think 10X before jumping to the PM track but what do you guys think? Which has a good progression in roles and salaries? Is it Product manager or Data Scientist?",
         "86",
         "53",
         "2021-12-09 00:52:29+00:00",
         "0.85",
         "kaggle_user"
        ],
        [
         "3",
         "rc324k",
         "datascience",
         "Is exact position title important?",
         "I am in the data science team and my current position is jr.data scientist. Before getting this position, I applied and interviewed for \"data scientist\" position at this current company, but at the end when they extended the offer, i was given \"jr.\" just because i was lacking experience level needed for \"data scientist\" in their goddamn hr system. (even though i was interviewed for exactly this position). I tried to negotiate but it didnt work. I accepted the position nonetheless and felt like this was bait and switch so now want to start applying again starting next year. Would me leaving out \"jr.\" part in my resume make a difference there? How could companies know?",
         "8",
         "21",
         "2021-12-08 22:45:24+00:00",
         "0.85",
         "kaggle_user"
        ],
        [
         "4",
         "sxal34",
         "datascience",
         "Has anybody ever tried to create a model to predict football matches results?",
         "Data of past matches, goals, assists, home team, away team, faults, n of shots etc.. are easily available online. However I have searched in this subreddit but found very few (and old) posts about the topic. \n\nI would really love to create one to predict the outcome of Bundesliga matches. Doing one right now just for fun \nand atm a crossvalidated model with Decision Trees gives me 59% correct predictions (win, draw, loss) with a simulated ROI of 29% (well.. at least in the simulation…).\n\nHas anybody tried to do sport prediction models with some success? (positive ROI on sport bets?)\nWhat are the challenges and obstacles in doing something like this? Is anybody interested in the topic?",
         "0",
         "2",
         "2022-02-20 20:30:13+00:00",
         "0.85",
         "kaggle_user"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swvi7j</td>\n",
       "      <td>datascience</td>\n",
       "      <td>STEM Career Change</td>\n",
       "      <td>I’m currently working as a field biologist for...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-02-20 07:17:13+00:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>kaggle_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rc6wjp</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Beast practices or frameworks for defining suc...</td>\n",
       "      <td>I'd love to learn what framework folks use for...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-09 02:00:48+00:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>kaggle_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rc5knh</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Data Scientist VS Product/Project manager role</td>\n",
       "      <td>Hey everyone, I am currently a Sr. Analyst and...</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>2021-12-09 00:52:29+00:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>kaggle_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rc324k</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Is exact position title important?</td>\n",
       "      <td>I am in the data science team and my current p...</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-12-08 22:45:24+00:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>kaggle_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxal34</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Has anybody ever tried to create a model to pr...</td>\n",
       "      <td>Data of past matches, goals, assists, home tea...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-20 20:30:13+00:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>kaggle_user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    subreddit                                              title  \\\n",
       "0  swvi7j  datascience                                 STEM Career Change   \n",
       "1  rc6wjp  datascience  Beast practices or frameworks for defining suc...   \n",
       "2  rc5knh  datascience     Data Scientist VS Product/Project manager role   \n",
       "3  rc324k  datascience                 Is exact position title important?   \n",
       "4  sxal34  datascience  Has anybody ever tried to create a model to pr...   \n",
       "\n",
       "                                            selftext  score  num_comments  \\\n",
       "0  I’m currently working as a field biologist for...      5             6   \n",
       "1  I'd love to learn what framework folks use for...      9             2   \n",
       "2  Hey everyone, I am currently a Sr. Analyst and...     86            53   \n",
       "3  I am in the data science team and my current p...      8            21   \n",
       "4  Data of past matches, goals, assists, home tea...      0             2   \n",
       "\n",
       "                created_utc  upvote_ratio       author  \n",
       "0 2022-02-20 07:17:13+00:00          0.85  kaggle_user  \n",
       "1 2021-12-09 02:00:48+00:00          0.85  kaggle_user  \n",
       "2 2021-12-09 00:52:29+00:00          0.85  kaggle_user  \n",
       "3 2021-12-08 22:45:24+00:00          0.85  kaggle_user  \n",
       "4 2022-02-20 20:30:13+00:00          0.85  kaggle_user  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize both dataframes to common columns\n",
    "standard_cols = ['id', 'subreddit', 'title', 'selftext', 'score', 'num_comments', \n",
    "                 'created_utc', 'upvote_ratio', 'author']\n",
    "\n",
    "frames = []\n",
    "\n",
    "if len(df_ds) > 0:\n",
    "    # Ensure all standard columns exist\n",
    "    for col in standard_cols:\n",
    "        if col not in df_ds.columns:\n",
    "            df_ds[col] = None\n",
    "    frames.append(df_ds[standard_cols])\n",
    "    print(f\"Data Science posts: {len(df_ds):,}\")\n",
    "\n",
    "if len(df_posts) > 0:\n",
    "    for col in standard_cols:\n",
    "        if col not in df_posts.columns:\n",
    "            df_posts[col] = None\n",
    "    frames.append(df_posts[standard_cols])\n",
    "    print(f\"Reddit Posts dataset: {len(df_posts):,}\")\n",
    "\n",
    "if frames:\n",
    "    df_raw = pd.concat(frames, ignore_index=True)\n",
    "else:\n",
    "    print(\"No data loaded! Using synthetic data as fallback...\")\n",
    "    from src.utils import generate_sample_data\n",
    "    df_raw = generate_sample_data(n_posts=5000, seed=42)\n",
    "\n",
    "# Clean up\n",
    "df_raw['selftext'] = df_raw['selftext'].fillna('')\n",
    "df_raw['title'] = df_raw['title'].fillna('')\n",
    "df_raw['score'] = pd.to_numeric(df_raw['score'], errors='coerce').fillna(0).astype(int)\n",
    "df_raw['num_comments'] = pd.to_numeric(df_raw['num_comments'], errors='coerce').fillna(0).astype(int)\n",
    "df_raw = df_raw.dropna(subset=['created_utc'])\n",
    "df_raw = df_raw.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"COMBINED DATASET\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Total posts: {len(df_raw):,}\")\n",
    "print(f\"Subreddits: {df_raw['subreddit'].nunique()}\")\n",
    "print(f\"Date range: {df_raw['created_utc'].min().date()} to {df_raw['created_utc'].max().date()}\")\n",
    "print(f\"\\nSubreddit distribution:\")\n",
    "print(df_raw['subreddit'].value_counts())\n",
    "print(f\"\\nScore stats:\")\n",
    "print(df_raw['score'].describe().round(1))\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3cd5e",
   "metadata": {},
   "source": [
    "## 1.4 Store in SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5c4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-25 15:40:58.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36mget_db_connection\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mConnected to database: ../data/raw/reddit_posts.db\u001b[0m\n",
      "\u001b[32m2026-02-25 15:40:58.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.utils\u001b[0m:\u001b[36minit_database\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mDatabase schema initialized\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 0 posts into database\n",
      "        n                   earliest                               latest\n",
      "0  301192  2008-06-23 18:50:07+00:00  2025-02-27 22:57:03.197627892+00:00\n"
     ]
    }
   ],
   "source": [
    "# Save to SQLite\n",
    "conn = get_db_connection('../data/raw/reddit_posts.db')\n",
    "init_database(conn)\n",
    "\n",
    "inserted = 0\n",
    "cursor = conn.cursor()\n",
    "for _, row in df_raw.iterrows():\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"INSERT OR IGNORE INTO posts (id, subreddit, title, selftext, score, num_comments, created_utc, upvote_ratio, author) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "            (str(row['id']), row['subreddit'], row['title'], row['selftext'],\n",
    "             int(row['score']), int(row['num_comments']), str(row['created_utc']),\n",
    "             float(row.get('upvote_ratio', 0.85)), str(row.get('author', 'unknown')))\n",
    "        )\n",
    "        inserted += cursor.rowcount\n",
    "    except Exception as e:\n",
    "        pass\n",
    "conn.commit()\n",
    "print(f\"Inserted {inserted:,} posts into database\")\n",
    "\n",
    "# Verify\n",
    "df_check = pd.read_sql(\"SELECT COUNT(*) as n, MIN(created_utc) as earliest, MAX(created_utc) as latest FROM posts\", conn)\n",
    "print(df_check)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2dc6e",
   "metadata": {},
   "source": [
    "## 1.5 Load Events Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b7d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech events timeline: 19 events\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "event",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "impact",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "94daa2d8-9b19-4157-be75-738dde4e5b3f",
       "rows": [
        [
         "0",
         "2024-06-10",
         "Apple WWDC 2024 — Apple Intelligence announced",
         "Apple",
         "product_launch",
         "high"
        ],
        [
         "1",
         "2024-06-18",
         "NVIDIA becomes most valuable company globally",
         "NVIDIA",
         "milestone",
         "high"
        ],
        [
         "2",
         "2024-07-18",
         "CrowdStrike outage crashes millions of Windows PCs",
         "Microsoft",
         "incident",
         "high"
        ],
        [
         "3",
         "2024-08-05",
         "Google found guilty of monopoly in DOJ antitrust case",
         "Google",
         "legal",
         "high"
        ],
        [
         "4",
         "2024-09-09",
         "Apple iPhone 16 launch event",
         "Apple",
         "product_launch",
         "medium"
        ],
        [
         "5",
         "2024-09-12",
         "OpenAI releases o1 reasoning model",
         "OpenAI",
         "product_launch",
         "high"
        ],
        [
         "6",
         "2024-09-24",
         "Meta Connect 2024 — Quest 3S and Orion AR glasses",
         "Meta",
         "product_launch",
         "medium"
        ],
        [
         "7",
         "2024-10-01",
         "Google Gemini app launches across 40 languages",
         "Google",
         "product_launch",
         "medium"
        ],
        [
         "8",
         "2024-10-28",
         "Microsoft reports Q1 FY25 earnings — cloud growth 33%",
         "Microsoft",
         "earnings",
         "medium"
        ],
        [
         "9",
         "2024-11-05",
         "US Presidential Election Day",
         null,
         "political",
         "high"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>event</th>\n",
       "      <th>company</th>\n",
       "      <th>category</th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>Apple WWDC 2024 — Apple Intelligence announced</td>\n",
       "      <td>Apple</td>\n",
       "      <td>product_launch</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>NVIDIA becomes most valuable company globally</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>milestone</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>CrowdStrike outage crashes millions of Windows...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>incident</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>Google found guilty of monopoly in DOJ antitru...</td>\n",
       "      <td>Google</td>\n",
       "      <td>legal</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>Apple iPhone 16 launch event</td>\n",
       "      <td>Apple</td>\n",
       "      <td>product_launch</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-09-12</td>\n",
       "      <td>OpenAI releases o1 reasoning model</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>product_launch</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-09-24</td>\n",
       "      <td>Meta Connect 2024 — Quest 3S and Orion AR glasses</td>\n",
       "      <td>Meta</td>\n",
       "      <td>product_launch</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>Google Gemini app launches across 40 languages</td>\n",
       "      <td>Google</td>\n",
       "      <td>product_launch</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>Microsoft reports Q1 FY25 earnings — cloud gro...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>earnings</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>US Presidential Election Day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>political</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              event    company  \\\n",
       "0  2024-06-10     Apple WWDC 2024 — Apple Intelligence announced      Apple   \n",
       "1  2024-06-18      NVIDIA becomes most valuable company globally     NVIDIA   \n",
       "2  2024-07-18  CrowdStrike outage crashes millions of Windows...  Microsoft   \n",
       "3  2024-08-05  Google found guilty of monopoly in DOJ antitru...     Google   \n",
       "4  2024-09-09                       Apple iPhone 16 launch event      Apple   \n",
       "5  2024-09-12                 OpenAI releases o1 reasoning model     OpenAI   \n",
       "6  2024-09-24  Meta Connect 2024 — Quest 3S and Orion AR glasses       Meta   \n",
       "7  2024-10-01     Google Gemini app launches across 40 languages     Google   \n",
       "8  2024-10-28  Microsoft reports Q1 FY25 earnings — cloud gro...  Microsoft   \n",
       "9  2024-11-05                       US Presidential Election Day        NaN   \n",
       "\n",
       "         category  impact  \n",
       "0  product_launch    high  \n",
       "1       milestone    high  \n",
       "2        incident    high  \n",
       "3           legal    high  \n",
       "4  product_launch  medium  \n",
       "5  product_launch    high  \n",
       "6  product_launch  medium  \n",
       "7  product_launch  medium  \n",
       "8        earnings  medium  \n",
       "9       political    high  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = pd.read_csv('../data/external/tech_events_timeline.csv')\n",
    "print(f\"Tech events timeline: {len(events)} events\")\n",
    "events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7475ca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 296,192 posts to data/processed/posts_raw_combined.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save combined raw data for next notebook\n",
    "df_raw.to_parquet('../data/processed/posts_raw_combined.parquet', index=False)\n",
    "print(f\"Saved {len(df_raw):,} posts to data/processed/posts_raw_combined.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252684e9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Successfully loaded real Reddit data from Kaggle datasets.\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Data sources | Kaggle (no API needed) |\n",
    "| Storage | SQLite + Parquet |\n",
    "\n",
    "**Next:** 02_eda_and_preprocessing.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
